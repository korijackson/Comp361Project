{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer - Cleaning  & Encoding\n",
    "**This handles the preprocessing for the UNSW-NB15 dataset.**\n",
    "\n",
    "**Task completed:**\n",
    "- Merges all dataset parts into one DataFrame\n",
    "- Drops duplicates and handles missing values\n",
    "- Encodes categorical feautures using Label Encoding\n",
    "- Saves the cleaned dataset as \"UNSW_NB15_full.csv\"\n",
    "- Visualizes the label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:12:41.541474Z",
     "start_time": "2025-10-30T13:12:41.536002Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load and Merge Dataset Parts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:12:46.445435Z",
     "start_time": "2025-10-30T13:12:41.550108Z"
    }
   },
   "source": [
    "# Load the already merged CSV\n",
    "df = pd.read_csv('UNSW-NB15 DataSet/UNSW-NB15_full.csv')\n",
    "print(\"Loaded dataset shape:\", df.shape)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sf/3m0szrln32z4sksr71t6fmy40000gn/T/ipykernel_77383/3709921906.py:2: DtypeWarning: Columns (1,3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('UNSW-NB15 DataSet/UNSW-NB15_full.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (2540047, 49)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Drop duplicates and Handle Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:08:54.313864Z",
     "start_time": "2025-10-30T15:08:52.967764Z"
    }
   },
   "source": [
    "# Separate categorical and numeric columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Fill missing values\n",
    "df[cat_cols] = df[cat_cols].fillna(\"Unknown\")\n",
    "df[num_cols] = df[num_cols].fillna(0)\n",
    "\n",
    "print(\"Missing values handled.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:12:49.507656Z",
     "start_time": "2025-10-30T13:12:47.655505Z"
    }
   },
   "source": [
    "# Each categorical column gets encoded\n",
    "for col in cat_cols:\n",
    "    encoder = LabelEncoder()\n",
    "    df[col] = encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "print(\"Categoricaal columns encoded individually.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoricaal columns encoded individually.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Convert and Scale Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:09:00.279513Z",
     "start_time": "2025-10-30T15:09:00.195027Z"
    }
   },
   "source": [
    "# Convert numeric-like columns to numbers \n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    except ValueError:\n",
    "        pass  # leave non-numeric/categorical columns as-is\n",
    "\n",
    "print(\"Numeric columns converted and ready for scaling.\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns converted and ready for scaling.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Split Data & Visualize Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:09:07.292736Z",
     "start_time": "2025-10-30T15:09:07.270865Z"
    }
   },
   "source": [
    "# Split into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "\n",
    "# Visualize label distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "y.value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution (Label Column)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Split into training/testing sets\u001B[39;00m\n\u001B[32m      2\u001B[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[43mX_scaled\u001B[49m, y, test_size=\u001B[32m0.3\u001B[39m, random_state=\u001B[32m42\u001B[39m\n\u001B[32m      4\u001B[39m )\n\u001B[32m      6\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTraining set shape:\u001B[39m\u001B[33m\"\u001B[39m, X_train.shape)\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTesting set shape:\u001B[39m\u001B[33m\"\u001B[39m, X_test.shape)\n",
      "\u001B[31mNameError\u001B[39m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
